// Code Snippet for loading data
val sqlContext = new org.apache.spark.sql.SQLContext(sc)
import sqlContext.implicits._
import org.apache.spark.sql._
val trainData = sc.textFile("/media/arpitarya07/New Volume1/SJSU_Studies/Sem5_CS298/Project_data/Filtered_csvs/trainingData_Label01.csv")
case class AutismTrain(vaers_id: String, symptom_text: String, label: Double)
val autismtrain = trainData.map(_.split(",")).map(p => AutismTrain(p(0),p(1),p(2).toDouble))
val autismtrain_DF = autismtrain.toDF()
autismtrain_DF.show()
autismtrain_DF.printSchema()

// Code Snippet for feature extraction
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.mllib.linalg.Vector
import org.apache.spark.sql.Row

val tokenizer = new Tokenizer().setInputCol("symptom_text").setOutputCol("symptom_words")
val hashingTF = new HashingTF().setNumFeatures(1000).setInputCol(tokenizer.getOutputCol).setOutputCol("features")

// Code Snippet for training model
val lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)
val pipeline = new Pipeline().setStages(Array(tokenizer,hashingTF,lr))
val model = pipeline.fit(autismtrain_DF)
val predictions = model.transform(autismtrain_DF)
predictions.select("vaers_id","symptom_text","label","symptom_words","features","prediction").collect().foreach(println)

// Code Snippet for parameter tuning and evaluation
import org.apache.spark.ml.evaluation.RegressionEvaluator
import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.mllib.util.MLUtils
import org.apache.spark.ml.tuning.ParamGridBuilder
import org.apache.spark.ml.tuning.CrossValidator
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val paramGrid = new ParamGridBuilder().addGrid(hashingTF.numFeatures, Array(1000,10000)).addGrid(lr.regParam, Array(0.05,0.2)).build()
val crossval = new CrossValidator().setEstimator(pipeline).setEvaluator(new BinaryClassificationEvaluator).setEstimatorParamMaps(paramGrid).setNumFolds(2)
val cvModel = crossval.fit(autismtrain_DF)
val evaluator = newBinaryClassificationEvaluator().setMetricName(“areaUnderROC”)
evaluator.evaluate(cvModel.transform(autismtrain_DF))
